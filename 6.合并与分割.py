import torch
import time


print('程序开始时间：',time.strftime('%Y-%m-%d %H:%M:%S')) #记录程序开始时间

print('---------------------------------------------------------------------------------------------------------------')

a = torch.rand(4,32,8).cuda()  # 生成三维张量a
b = torch.rand(5,32,8).cuda()  # 生成三维张量b
print('合并前a的形状：',a.shape)  # 输出a的形状
print('合并前b的形状：',b.shape)  # 输出b的形状
a_b = torch.cat([a,b],dim=0).cuda()  # 指定a与b在维度0（第一个维度）上合并。除了合并的维度外，其它维度必须匹配。
print('a与b合并后的形状：',a_b.shape)  # 输出a和b合并后的张量形状
a2 = torch.rand(4,32,16,32).cuda()  # 生成四维张量a
b2 = torch.rand(4,32,16,32).cuda()  # 生成四维张量b
print('合并前a2的形状：',a2.shape)  # 输出a2的形状
print('合并前b2的形状：',b2.shape)  # 输出b2的形状
a2_b2 = torch.cat([a2,b2],dim=2).cuda()  # 指定a2与b2在维度2（第三个维度）上合并。除了合并的维度外，其它维度必须匹配。
print('a2与b2合并后的形状：',a2_b2.shape)  # 输出a2和b2合并后的张量形状

print('---------------------------------------------------------------------------------------------------------------')

print('合并前a2的形状：',a2.shape)  # 输出a2的形状
print('合并前b2的形状：',b2.shape)  # 输出b2的形状
a2_b2_2 = torch.stack([a2,b2],dim =0).cuda()  # 用stack合并，会在dim=n的n维之前创建一个新的维度，这要求原先的两个张量维度信息必须一致。
print('另一种方式合并a2和b2后的张量形状：',a2_b2_2.shape)  # 输出a2和b2用stack合并后的张量形状


print('---------------------------------------------------------------------------------------------------------------')

print('之前合并a2和b2后的张量形状：',a2_b2_2.shape)  # 输出a2和b2用stack合并后的张量形状
a_s1, b_s1 = a2_b2_2.split(1,dim=0) # 以1为单位在0维（第一个维度）上拆分
a_s1 = a_s1.cuda()  # 搬运到GPU
b_s1 = b_s1.cuda()  # 搬运到GPU
print('拆分形成的新a的形状：',a_s1.shape)  # 输出拆分后的a
print('拆分形成的新b的形状：',b_s1.shape)  # 输出拆分后的b
a_s2, b_s2, c_s2 = a2_b2_2.split([6,8,2],dim=3) # 在第三维上进行拆分，拆分后的三个张量的第三维分别为6、8和2，
# 即[2,4,32,16,32]拆分为[2，4，32，6，32]、[2，4，32，8，32]和[2，4，32，2，32].
a_s2 = a_s2.cuda()  # 搬运到GPU
b_s2 = b_s2.cuda()  # 搬运到GPU
c_s2 = c_s2.cuda()  # 搬运到GPU
print('另一种拆分形成的新a的形状：',a_s2.shape)  # 输出拆分后的a
print('另一种拆分形成的新b的形状：',b_s2.shape)  # 输出拆分后的b
print('另一种拆分形成的新c的形状：',c_s2.shape)  # 输出拆分后的c

print('---------------------------------------------------------------------------------------------------------------')

print('之前合并a2和b2后的张量形状：',a2_b2_2.shape)  # 输出a2和b2用stack合并后的张量形状
a_s3,b_s3,c_s3,d_s3 = a2_b2_2.chunk(4,dim=2)  # 按数量拆分，即在第三维上按每个新张量6的数量拆分，32/4=8，所以4个新张量的第三维会为8。
a_s3 = a_s3.cuda()  # 搬运到GPU
b_s3 = b_s3.cuda()  # 搬运到GPU
c_s3 = c_s3.cuda()  # 搬运到GPU
d_s3 = d_s3.cuda()  # 搬运到GPU
print('另一种按数值拆分形成的新a的形状：',a_s3.shape)  # 输出拆分后的a
print('另一种按数值拆分形成的新b的形状：',b_s3.shape)  # 输出拆分后的b
print('另一种按数值拆分形成的新c的形状：',c_s3.shape)  # 输出拆分后的c
print('另一种按数值拆分形成的新d的形状：',d_s3.shape)  # 输出拆分后的c

print('---------------------------------------------------------------------------------------------------------------')




print('程序结束时间：',time.strftime('%Y-%m-%d %H:%M:%S'))  # 记录程序结束时间